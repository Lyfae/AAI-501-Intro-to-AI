{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import PIL\n",
    "import random\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the constants: \n",
    "# Initial Learning Rate\n",
    "# Epochs\n",
    "# Batch Size\n",
    "# Length \n",
    "# Width \n",
    "INITIAL_LEARINGRATE = .001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LENGTH = 224\n",
    "WIDTH = 224"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images without covid\n",
    "wOut_Covid = list(pathlib.Path(\"../DATA\").glob('0/*'))\n",
    "# images with covid\n",
    "w_Covid = list(pathlib.Path(\"../DATA\").glob('1/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(wOut_Covid), 'images without Covid')\n",
    "print('There are', len(w_Covid), 'images without Covid')\n",
    "\n",
    "plt.bar(['Without Covid', 'With Covid'], [len(wOut_Covid), len(w_Covid)], align = 'center')\n",
    "plt.title('Number of images with and without Covid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image path for the images without covid\n",
    "image_dir = \"../DATA/0/\"\n",
    "\n",
    "# Create a 4x4 subplot\n",
    "fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "axs = axs.ravel() # flatten the axes array\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [filename for filename in os.listdir(image_dir)]\n",
    "\n",
    "# Randomly select 16 images from the list\n",
    "selected_files = random.sample(image_files, k=16)\n",
    "\n",
    "# Loop through the selected files\n",
    "for i, filename in enumerate(selected_files):\n",
    "    # Load the image using matplotlib\n",
    "    img = plt.imread(os.path.join(image_dir, filename))\n",
    "\n",
    "    # Display the image in the appropriate subplot\n",
    "    axs[i].imshow(img.astype(\"uint8\"))\n",
    "    axs[i].axis('off')\n",
    "     \n",
    "# show the plot\n",
    "plt.suptitle('Dataset of Images Without Covid')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image path for the images with covid\n",
    "image_dir = \"../DATA/1/\"\n",
    "\n",
    "# Create a 4x4 subplot\n",
    "fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "axs = axs.ravel() # flatten the axes array\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [filename for filename in os.listdir(image_dir)]\n",
    "\n",
    "# Randomly select 16 images from the list\n",
    "selected_files = random.sample(image_files, k=16)\n",
    "\n",
    "# Loop through the selected files\n",
    "for i, filename in enumerate(selected_files):\n",
    "    # Load the image using matplotlib\n",
    "    img = plt.imread(os.path.join(image_dir, filename))\n",
    "\n",
    "    # Display the image in the appropriate subplot\n",
    "    axs[i].imshow(img.astype(\"uint8\"))\n",
    "    axs[i].axis('off')\n",
    "     \n",
    "# show the plot\n",
    "plt.suptitle('Dataset of Images With Covid')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the images and put them into lists\n",
    "image_path = list(paths.list_images(r\"..\\DATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for the data and the labels\n",
    "data = list()\n",
    "labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to loop over all the images in the files and then rescale them to a 224x224 aspect ratio. This will be done via the CV library\n",
    "for x in image_path:\n",
    "    # getting the classlabel\n",
    "    label = x.split(os.path.sep)[-2]\n",
    "\n",
    "    # now, we load the image, change the color to RGB and then resize it\n",
    "    image = cv2.imread(x)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image,(LENGTH,WIDTH))\n",
    "\n",
    "    # update our label and data list\n",
    "    labels.append(label)\n",
    "    data.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data and labels to Numpy Arrays while scaling the pixel intensity\n",
    "data = np.array(data) / 255.0 # 255 RGB colors\n",
    "data.reshape(-1,1)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding the models\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our train and test data. Using standard practice, 80% of the dataset will be used for training \n",
    "# while the 20% will be used for testing\n",
    "trainX, testX, trainY, testY = train_test_split(data,labels,test_size=.2, stratify=labels,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "train_augment = ImageDataGenerator(\n",
    "    rotation_range =15,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Model using VGG16 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL IS HERE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the ADAM optimizer to optimize\n",
    "optimizer = Adam(learning_rate=INITIAL_LEARINGRATE, weight_decay = INITIAL_LEARINGRATE/EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the head of the network\n",
    "head = model.fit(\n",
    "    train_augment.flow(trainX,trainY,batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch = len(trainX)//BATCH_SIZE,\n",
    "    validation_data = (testX,testY),\n",
    "    validation_steps = len(testX) // BATCH_SIZE,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using the trained model\n",
    "predict = model.predict(testX,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image, find the index of the label corresponding with the largest predicted probability\n",
    "predict = np.argmax(predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now represent the prediction in a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1),predict,target_names=lb.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix For Statistical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix consisting of accuracy, sensitivity, and specificity. \n",
    "confusionMatrix =confusion_matrix(testY.argmax(axis=1),predict)\n",
    "total = sum(sum(confusionMatrix))\n",
    "\n",
    "# caculate accuracy, sensitivity, and specificity\n",
    "accuracy = (confusionMatrix[0,0] + confusionMatrix[1,1]) / total\n",
    "sensitivity = confusionMatrix[0,0] / (confusionMatrix[0,0] + confusionMatrix[0,1])\n",
    "specificity = confusionMatrix[1,1] / (confusionMatrix[1,0] + confusionMatrix[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the output\n",
    "print(confusionMatrix)\n",
    "print(\"Accuracy:    \", round(accuracy,3))\n",
    "print(\"Sensitivity: \", round(sensitivity,3))\n",
    "print(\"Specificity: \", round(specificity,3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Visual Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for visual representation\n",
    "plt.plot(np.arange(0, EPOCHS), head.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), head.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), head.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), head.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
